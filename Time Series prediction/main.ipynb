{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14cbeee-3fb1-46d9-8eb3-fcdbccdc1197",
   "metadata": {},
   "source": [
    "# IT3030 Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd3845-595a-4557-aab8-7e7bd723f83e",
   "metadata": {},
   "source": [
    "## set working path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d9801ef-f2e0-4f0b-8a46-ed05525c9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/jupyter/DeepLearning/Time Series prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8b08e-1268-4250-ba44-42f66920af05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "41d38eaa-568f-498f-8b91-ca142114d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# import utility functions\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a80001-2808-49bf-b570-4c2dd0fa42ed",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c8ae2215-57a7-4fa9-aa8e-08d5c86b03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(sys.path[0] + '/data/no1_train.csv')\n",
    "validation = pd.read_csv(sys.path[0] + '/data/no1_validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dff386-a062-4345-b313-cf20944b32e1",
   "metadata": {},
   "source": [
    "## pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8561169c-7dda-45ae-b884-b1928712eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, df_val):\n",
    "    # convert start_time to datetime\n",
    "    df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "    df_val['start_time'] = pd.to_datetime(df_val['start_time'])\n",
    "\n",
    "    # clamp the target variable y\n",
    "    lower, upper = df['y'].quantile(0.005),  df['y'].quantile(0.995)\n",
    "    df['y'].clip(lower, upper, inplace=True)\n",
    "    df_val['y'].clip(lower, upper, inplace=True)\n",
    "\n",
    "    \n",
    "    # Normalize with a min max scaler for the planned power production\n",
    "    min_max_var = ['hydro', 'micro', 'thermal', 'wind', 'river', 'total']\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df[min_max_var] = min_max_scaler.fit_transform(df[min_max_var])\n",
    "    df_val[min_max_var] = min_max_scaler.transform(df_val[min_max_var])\n",
    "    \n",
    "    \n",
    "    # Normalize with a standard scaler for the system regulation, planned flow and imbalance predictions\n",
    "    standard_var = ['sys_reg', 'flow', 'y']\n",
    "    standard_scaler = StandardScaler()\n",
    "    df[standard_var] = standard_scaler.fit_transform(df[standard_var])\n",
    "    df_val[standard_var] = standard_scaler.transform(df_val[standard_var])\n",
    "    \n",
    "    \n",
    "    # Add time features\n",
    "    df['time_of_day']  = df.start_time.dt.hour\n",
    "    df['time_of_week'] = df.start_time.dt.day_name()\n",
    "    df['time_of_year'] = df.start_time.dt.month_name()\n",
    "    df_val['time_of_day']  = df_val.start_time.dt.hour\n",
    "    df_val['time_of_week'] = df_val.start_time.dt.day_name()\n",
    "    df_val['time_of_year'] = df_val.start_time.dt.month_name()\n",
    "    \n",
    "    ## Add one-hot encoding for season and time of week\n",
    "    \n",
    "    #df['is_summer'] = df['time_of_year'].isin(['June', 'July', 'August'])\n",
    "    df['is_fall'] = df['time_of_year'].isin(['September', 'October', 'November'])\n",
    "    df['is_winter'] = df['time_of_year'].isin(['December', 'January', 'February'])\n",
    "    df['is_spring'] = df['time_of_year'].isin(['March', 'April', 'May'])\n",
    "    #df_val['is_summer'] = df_val['time_of_year'].isin(['June', 'July', 'August'])\n",
    "    df_val['is_fall'] = df_val['time_of_year'].isin(['September', 'October', 'November'])\n",
    "    df_val['is_winter'] = df_val['time_of_year'].isin(['December', 'January', 'February'])\n",
    "    df_val['is_spring'] = df_val['time_of_year'].isin(['March', 'April', 'May'])\n",
    "    \n",
    "    #df['is_weekday'] = df['time_of_week'].isin(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])\n",
    "    df['is_weekend'] = df['time_of_week'].isin(['Saturday', 'Sunday'])\n",
    "    #df_val['is_weekday'] = df_val['time_of_week'].isin(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])\n",
    "    df_val['is_weekend'] = df_val['time_of_week'].isin(['Saturday', 'Sunday'])\n",
    "    \n",
    "    #df['is_night'] = np.logical_and(0 <= df['time_of_day'], df['time_of_day'] < 6)\n",
    "    df['is_morning'] = np.logical_and(6 <= df['time_of_day'], df['time_of_day'] < 12)\n",
    "    df['is_midday'] = np.logical_and(12 <= df['time_of_day'], df['time_of_day'] < 18)\n",
    "    df['is_evening'] = np.logical_and(18 <= df['time_of_day'], df['time_of_day'] <= 23)\n",
    "    #df_val['is_night'] = np.logical_and(0 <= df_val['time_of_day'], df['time_of_day'] < 6)\n",
    "    df_val['is_morning'] = np.logical_and(6 <= df_val['time_of_day'], df['time_of_day'] < 12)\n",
    "    df_val['is_midday'] = np.logical_and(12 <= df_val['time_of_day'], df['time_of_day'] < 18)\n",
    "    df_val['is_evening'] = np.logical_and(18 <= df_val['time_of_day'], df['time_of_day'] <= 23)\n",
    "    \n",
    "\n",
    "    ## Add previous y\n",
    "    df['previous_y'] = df['y'].shift(1)\n",
    "    df.loc[0,'previous_y'] = df.loc[1,'previous_y']\n",
    "    df_val['previous_y'] = df_val['y'].shift(1)\n",
    "    df_val.loc[0,'previous_y'] = df_val.loc[1,'previous_y']\n",
    "    \n",
    "    # Add lag features\n",
    "    \n",
    "    # 24 hour lag imbalance (= 288 periods of 5 min)\n",
    "    df['lag_24_hours_y'] = df['y'].diff(periods=288)\n",
    "    df.loc[0:287,'lag_24_hours_y'] = 0\n",
    "    df_val['lag_24_hours_y'] = df_val['y'].diff(periods=288)\n",
    "    df_val.loc[0:287,'lag_24_hours_y'] = 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "313056f5-8b93-45e3-93f6-c8f3992af6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_time        datetime64[ns]\n",
       "hydro                    float64\n",
       "micro                    float64\n",
       "thermal                  float64\n",
       "wind                     float64\n",
       "river                    float64\n",
       "total                    float64\n",
       "y                        float64\n",
       "sys_reg                  float64\n",
       "flow                     float64\n",
       "time_of_day                int64\n",
       "time_of_week              object\n",
       "time_of_year              object\n",
       "is_fall                     bool\n",
       "is_winter                   bool\n",
       "is_spring                   bool\n",
       "is_weekend                  bool\n",
       "is_morning                  bool\n",
       "is_midday                   bool\n",
       "is_evening                  bool\n",
       "previous_y               float64\n",
       "lag_24_hours_y           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(train, validation)\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "72bdd856-0b84-4f1d-a00c-a2d7a3afff13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              NaN\n",
       "1         1.079343\n",
       "2         1.043034\n",
       "3         1.022842\n",
       "4         0.934014\n",
       "            ...   \n",
       "225083    0.430890\n",
       "225084    0.432809\n",
       "225085    0.392099\n",
       "225086    0.281588\n",
       "225087    0.306456\n",
       "Name: previous_y, Length: 225088, dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.previous_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e607e27-f73f-4351-9d1a-b7a30d64acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n1_seq(df, n_seq, inputs, outputs):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    df (pandas dataframe): contains the inputs and outputs for each time step\n",
    "    \n",
    "    OUTPUTS:\n",
    "    x (numpy ndarray): (n_seq)\n",
    "    '''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9627b609-c2ca-4a91-8cb0-dda5c6402273",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(sys.path[0] + '/data/no1_train.csv')\n",
    "prep_dtypes(train)\n",
    "clamp_data(train, 'y', 0.005, 0.995)\n",
    "normalize_data(train, variable_list = ['hydro', 'micro', 'thermal', 'wind', 'river', 'total'])\n",
    "\n",
    "add_time_features(train)\n",
    "add_lag_features(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8a770d6a-159a-4a13-8271-7e05aa24e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.11111111]\n",
      " [0.22222222]\n",
      " [0.33333333]\n",
      " [0.44444444]\n",
      " [0.55555556]\n",
      " [0.66666667]\n",
      " [0.77777778]\n",
      " [0.88888889]\n",
      " [1.        ]]\n",
      "MinMaxScaler()\n",
      "[[-0.11111111]\n",
      " [ 0.        ]\n",
      " [ 0.11111111]\n",
      " [ 0.22222222]\n",
      " [ 0.33333333]\n",
      " [ 0.44444444]\n",
      " [ 0.55555556]\n",
      " [ 0.66666667]\n",
      " [ 0.77777778]\n",
      " [ 0.88888889]\n",
      " [ 1.        ]\n",
      " [ 1.11111111]]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(10).reshape((-1,1))\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x = scaler.fit_transform(x)\n",
    "print(x)\n",
    "y = np.arange(12).reshape((-1,1))-1\n",
    "y = scaler.transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c07854a9-2edf-40b4-87d1-cb8491538f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "\n",
    "# start_time : The timestamp of each datum\n",
    "# hydro      : The planned reservoir hydropower production at the time step.\n",
    "# micro      : The planned small-scale production at the time step.\n",
    "# river      : The planned run-of-river hydropower production at the time step.\n",
    "# thermal    : The planned thermal power plant production at the time step.\n",
    "# wind       : The planned wind power plant production at the time step.\n",
    "# total      : The total planned production at the time step.\n",
    "# sys_reg    : The planned system regulation at the time step.\n",
    "# flow       : The planned total power flow in or out of the current area.\n",
    "\n",
    "# y          : The estimated open loop power grid imbalance at the time step.\n",
    "\n",
    "\n",
    "## TO DO\n",
    "# 1. Define previous_y, the estimated power grid imbalance at the previous step. (DONE)\n",
    "# 2. Clamb the values of the target series \"y\" to exclude noisy spikes in magnitude. (DONE)\n",
    "# 3. Write code for normalizing / standardizing the input data. ()\n",
    "# 4. Implement date time features. -> time_of_day, time_of_week, time_of_year (DONE)\n",
    "# 5. Implement at least two lag features of power imbalance. -> 24 hour lag? 1 week lag? 48 hours lag? (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e2af0-e105-401e-8499-88118e5b3dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
